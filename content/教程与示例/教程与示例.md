# 教程与示例

> **引用文件**
> **本文档中引用的文件**

- [automatic_control.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/automatic_control.py)
- [manual_control.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/manual_control.py)
- [generate_traffic.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/generate_traffic.py)
- [sensor_synchronization.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/sensor_synchronization.py)
- [visualize_multiple_sensors.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/visualize_multiple_sensors.py)
- [visualize_radar.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/visualize_radar.py)
- [open3d_lidar.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/open3d_lidar.py)
- [start_quickstart.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/start_quickstart.md)
- [python_api.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/python_api.md)
- [core_actors.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/core_actors.md)
- [core_sensors.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/core_sensors.md)

## 目录

1. [简介](#简介)
2. [CARLA 基础概念](#carla基础概念)
3. [连接到仿真器](#连接到仿真器)
4. [生成和控制车辆](#生成和控制车辆)
5. [添加和处理传感器](#添加和处理传感器)
6. [高级主题](#高级主题)
7. [常见问题与最佳实践](#常见问题与最佳实践)
8. [结论](#结论)

## 简介

本教程旨在为用户提供一个全面的指南，帮助用户掌握 CARLA 仿真器的关键使用场景。从基本概念开始，逐步过渡到高级主题，涵盖连接到仿真器、生成车辆、控制车辆、添加传感器和处理传感器数据等基本操作。通过实际示例代码，如`automatic_control.py`中的自动驾驶逻辑和`manual_control.py`中的手动控制实现，详细解释代码的关键部分及其工作原理。此外，还包括交通生成、传感器同步和自定义场景创建等高级主题。确保内容对初学者友好，同时为经验丰富的开发者提供足够的技术深度。

## CARLA 基础概念

CARLA（Car Learning to Act）是一个开源的自动驾驶仿真平台，基于 Unreal Engine 构建，提供了丰富的功能和工具，用于开发和测试自动驾驶算法。CARLA 的核心概念包括：

- **Actor**：在仿真中扮演角色的任何实体，包括车辆、行人、传感器、交通标志等。
- **Blueprint**：用于创建 Actor 的模板，包含 Actor 的属性和行为。
- **World**：仿真环境，包含地图、天气、时间等信息。
- **Sensor**：用于收集环境数据的设备，如摄像头、激光雷达、雷达等。
- **Client**：与仿真服务器通信的客户端，用于发送命令和接收数据。

### Actor

Actor 是 CARLA 中的基本单元，可以是车辆、行人、传感器等。每个 Actor 都有一个唯一的 ID，并且可以通过`carla.Actor`类进行管理和操作。Actor 的生命周期包括创建、使用和销毁。

### Blueprint

Blueprint 是用于创建 Actor 的模板，包含 Actor 的属性和行为。可以通过`carla.BlueprintLibrary`获取可用的 Blueprint，并通过`carla.ActorBlueprint`设置和获取属性。

### World

World 是仿真环境，包含地图、天气、时间等信息。可以通过`carla.World`类获取和设置这些信息。World 还负责管理 Actor 的生命周期。

### Sensor

Sensor 是用于收集环境数据的设备，如摄像头、激光雷达、雷达等。每个 Sensor 都有一个`listen`方法，用于接收和处理数据。

### Client

Client 是与仿真服务器通信的客户端，用于发送命令和接收数据。可以通过`carla.Client`类连接到服务器，并执行各种操作。

## 连接到仿真器

要使用 CARLA，首先需要连接到仿真服务器。以下是连接到仿真器的基本步骤：

1. **安装 CARLA**：根据官方文档安装 CARLA，确保系统满足最低要求。
2. **启动仿真服务器**：在终端中运行`./CarlaUE4.sh`（Linux）或`CarlaUE4.exe`（Windows）启动仿真服务器。
3. **连接到服务器**：使用 Python 客户端连接到服务器。

```python
import carla

# 创建客户端
client = carla.Client('localhost', 2000)
client.set_timeout(10.0)

# 获取世界对象
world = client.get_world()
```

**Section sources**

- [start_quickstart.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/start_quickstart.md#running-carla)
- [python_api.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/python_api.md#carla.Client.__init__)

## 生成和控制车辆

### 生成车辆

生成车辆需要选择一个合适的 Blueprint，并设置其属性。以下是生成车辆的步骤：

1. **获取 Blueprint 库**：通过`world.get_blueprint_library()`获取 Blueprint 库。
2. **选择 Blueprint**：通过`blueprint_library.filter()`选择一个合适的 Blueprint。
3. **设置属性**：通过`blueprint.set_attribute()`设置车辆的属性，如颜色、生成代数等。
4. **生成车辆**：通过`world.spawn_actor()`生成车辆。

```python
# 获取Blueprint库
blueprint_library = world.get_blueprint_library()

# 选择车辆Blueprint
vehicle_bp = blueprint_library.filter('vehicle.*')[0]

# 设置车辆颜色
color = random.choice(vehicle_bp.get_attribute('color').recommended_values)
vehicle_bp.set_attribute('color', color)

# 生成车辆
spawn_point = random.choice(world.get_map().get_spawn_points())
vehicle = world.spawn_actor(vehicle_bp, spawn_point)
```

### 控制车辆

控制车辆可以通过手动控制或自动驾驶模式实现。以下是两种控制方式的示例：

#### 手动控制

手动控制通过键盘输入来控制车辆。`manual_control.py`示例展示了如何实现手动控制。

```python
import pygame
from pygame.locals import K_w, K_s, K_a, K_d, K_SPACE

# 初始化Pygame
pygame.init()
display = pygame.display.set_mode((800, 600))

# 主循环
while True:
    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            break
        elif event.type == pygame.KEYDOWN:
            if event.key == K_w:
                vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))
            elif event.key == K_s:
                vehicle.apply_control(carla.VehicleControl(brake=1.0, steer=0.0))
            elif event.key == K_a:
                vehicle.apply_control(carla.VehicleControl(throttle=0.5, steer=-1.0))
            elif event.key == K_d:
                vehicle.apply_control(carla.VehicleControl(throttle=0.5, steer=1.0))
            elif event.key == K_SPACE:
                vehicle.apply_control(carla.VehicleControl(hand_brake=True))
    pygame.display.flip()
```

#### 自动驾驶

自动驾驶通过 Traffic Manager 实现。`automatic_control.py`示例展示了如何实现自动驾驶。

```python
# 获取Traffic Manager
traffic_manager = client.get_trafficmanager()

# 设置自动驾驶模式
vehicle.set_autopilot(True)

# 设置Traffic Manager参数
traffic_manager.set_global_distance_to_leading_vehicle(2.5)
traffic_manager.set_synchronous_mode(True)
```

**Section sources**

- [automatic_control.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/automatic_control.py)
- [manual_control.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/manual_control.py)
- [core_actors.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/core_actors.md#vehicles)

## 添加和处理传感器

### 添加传感器

添加传感器需要选择合适的 Sensor Blueprint，并设置其属性。以下是添加传感器的步骤：

1. **获取 Sensor Blueprint**：通过`blueprint_library.find()`获取 Sensor Blueprint。
2. **设置属性**：通过`blueprint.set_attribute()`设置 Sensor 的属性，如图像大小、视场角等。
3. **生成 Sensor**：通过`world.spawn_actor()`生成 Sensor，并将其附加到车辆上。
4. **监听数据**：通过`sensor.listen()`方法监听 Sensor 数据。

```python
# 获取Sensor Blueprint
camera_bp = blueprint_library.find('sensor.camera.rgb')

# 设置Sensor属性
camera_bp.set_attribute('image_size_x', '800')
camera_bp.set_attribute('image_size_y', '600')
camera_bp.set_attribute('fov', '110')

# 生成Sensor
camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)

# 监听数据
camera.listen(lambda image: image.save_to_disk('output/%06d.png' % image.frame))
```

### 处理传感器数据

处理传感器数据可以通过回调函数实现。以下是处理摄像头数据的示例：

```python
def process_image(image):
    # 转换图像格式
    image.convert(carla.ColorConverter.Raw)

    # 将图像数据转换为NumPy数组
    array = np.frombuffer(image.raw_data, dtype=np.dtype("uint8"))
    array = np.reshape(array, (image.height, image.width, 4))
    array = array[:, :, :3]
    array = array[:, :, ::-1]

    # 显示图像
    surface = pygame.surfarray.make_surface(array.swapaxes(0, 1))
    display.blit(surface, (0, 0))
    pygame.display.flip()

# 监听数据
camera.listen(process_image)
```

**Section sources**

- [visualize_multiple_sensors.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/visualize_multiple_sensors.py)
- [core_sensors.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/core_sensors.md#sensors-step-by-step)

## 高级主题

### 交通生成

交通生成可以通过`generate_traffic.py`示例实现。该示例展示了如何生成大量车辆和行人，并设置它们的行为。

```python
# 生成车辆
for n, transform in enumerate(spawn_points):
    if n >= args.number_of_vehicles:
        break
    blueprint = random.choice(blueprints)
    if blueprint.has_attribute('color'):
        color = random.choice(blueprint.get_attribute('color').recommended_values)
        blueprint.set_attribute('color', color)
    if blueprint.has_attribute('driver_id'):
        driver_id = random.choice(blueprint.get_attribute('driver_id').recommended_values)
        blueprint.set_attribute('driver_id', driver_id)
    blueprint.set_attribute('role_name', 'autopilot')

    # 生成车辆
    batch.append(SpawnActor(blueprint, transform)
                .then(SetAutopilot(FutureActor, True, traffic_manager.get_port())))

# 应用批量命令
for response in client.apply_batch_sync(batch, synchronous_master):
    if response.error:
        logging.error(response.error)
    else:
        vehicles_list.append(response.actor_id)
```

### 传感器同步

传感器同步可以通过`sensor_synchronization.py`示例实现。该示例展示了如何同步多个传感器的数据。

```python
# 创建传感器队列
sensor_queue = Queue()

# 定义传感器回调
def sensor_callback(sensor_data, sensor_queue, sensor_name):
    sensor_queue.put((sensor_data.frame, sensor_name))

# 生成传感器
cam_bp = blueprint_library.find('sensor.camera.rgb')
cam = world.spawn_actor(cam_bp, carla.Transform(), attach_to=vehicle)
cam.listen(lambda data: sensor_callback(data, sensor_queue, "camera"))

lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')
lidar = world.spawn_actor(lidar_bp, carla.Transform(), attach_to=vehicle)
lidar.listen(lambda data: sensor_callback(data, sensor_queue, "lidar"))

# 主循环
while True:
    world.tick()
    w_frame = world.get_snapshot().frame
    print("\nWorld's frame: %d" % w_frame)

    try:
        for _ in range(len(sensor_list)):
            s_frame = sensor_queue.get(True, 1.0)
            print("    Frame: %d   Sensor: %s" % (s_frame[0], s_frame[1]))
    except Empty:
        print("    Some of the sensor information is missed")
```

### 自定义场景创建

自定义场景创建可以通过修改地图和添加自定义 Actor 实现。`open3d_lidar.py`示例展示了如何使用 Open3D 可视化激光雷达数据。

```python
# 生成激光雷达
lidar_bp = generate_lidar_bp(args, world, blueprint_library, delta)
lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=vehicle)

# 定义激光雷达回调
def lidar_callback(point_cloud, point_list):
    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))
    data = np.reshape(data, (int(data.shape[0] / 4), 4))

    # 提取强度信息
    intensity = data[:, -1]
    intensity_col = 1.0 - np.log(intensity) / np.log(np.exp(-0.004 * 100))
    int_color = np.c_[
        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 0]),
        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 1]),
        np.interp(intensity_col, VID_RANGE, VIRIDIS[:, 2])]

    # 提取3D数据
    points = data[:, :-1]
    points[:, :1] = -points[:, :1]

    point_list.points = o3d.utility.Vector3dVector(points)
    point_list.colors = o3d.utility.Vector3dVector(int_color)

# 监听数据
lidar.listen(lambda data: lidar_callback(data, point_list))
```

**Section sources**

- [generate_traffic.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/generate_traffic.py)
- [sensor_synchronization.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/sensor_synchronization.py)
- [open3d_lidar.py](https://github.com/carla-simulator/carla/blob/ue5-dev/PythonAPI/examples/open3d_lidar.py)

## 常见问题与最佳实践

### 常见问题

1. **无法连接到服务器**：确保服务器已启动，并且客户端和服务器在同一网络中。
2. **传感器数据丢失**：检查传感器的`sensor_tick`属性，确保数据采集频率合适。
3. **车辆失控**：检查车辆的物理控制参数，确保设置正确。

### 最佳实践

1. **使用同步模式**：在需要精确控制的场景中，使用同步模式可以避免数据丢失。
2. **合理设置传感器属性**：根据应用场景合理设置传感器的属性，如图像大小、视场角等。
3. **定期清理 Actor**：在仿真结束后，及时销毁所有 Actor，避免资源浪费。

**Section sources**

- [start_quickstart.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/start_quickstart.md#running-carla)
- [core_sensors.md](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/core_sensors.md#sensors-step-by-step)

## 结论

本教程详细介绍了 CARLA 仿真器的关键使用场景，从基本概念开始，逐步过渡到高级主题。通过实际示例代码，帮助用户掌握连接到仿真器、生成车辆、控制车辆、添加传感器和处理传感器数据等基本操作。希望本教程能为用户提供有价值的指导，帮助他们在自动驾驶领域取得更好的成果。
